name: GraphVAE
_target_: models.graphVAE.LightningGraphVAE

# these parameters should not change
configuration:

  shared_parameters:
    latent_dim: 12 #64
    graph_max_nodes: ${datasets.max_nodes}
    node_attributes: ${datasets.node_attributes}

  model:
    gradient_type: pathwise
    num_variational_samples: 1
    augmented_inputs: False
    augmented_transforms: [[[1, 0], [0, 1]],
                           [[1, 0], [0, -1]],
                           [[0, 1], [1, 0]],
                           [[0, 1], [-1, 0]],
                           [[-1, 0], [0, 1]],
                           [[-1, 0], [0, -1]],
                           [[0, -1], [1, 0]],
                           [[0, -1], [-1, 0]]]

  encoder:
    attributes: ["empty", "start", "goal"]
    #attributes_mapping: [0, 2, 3]
    gnn:
      architecture: GIN
      num_layers: 5 #8
      layer_dim: 8
      num_mlp_layers: 2
      final_dropout: 0
      learn_eps: False
      graph_pooling: mean
      neighbor_pooling: sum

    mlp:
      num_layers: 2
      layer_dim: [ 1024, 128 ] #[ 1024, 256 ]

  decoder:
    adjacency: reduced #[full, reduced, null]
    attributes: ["start", "goal"]#["empty", "start", "goal"]
    #attributes_mapping: [2, 3] #predict start, goal
    distributions: ["one_hot_categorical", "one_hot_categorical"]
    distributions_domains: ["nodes", "nodes"]
    output_dim: #this should be computed according to adjacency, data.graph_max_nodes
      adjacency: null # Auto (max_node-1)*2
      attributes: ${datasets.max_nodes} # Auto (max_nodes)
    architecture: MLP
    num_layers: 2 #not counting the final multihead layer
    layer_dim: [ 128, 256 ] # [ 256, 1024 ]

# these can change between runs
hyperparameters:
  loss:
    elbo_coeffs:
      A: 1
      Fx: [1, 1]
      beta: 1